{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4PEceAkRUnsTz4ne8+JL7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsdivya1309/Machine-Learning/blob/main/LLMs/Text%20Classification/Text_Classification_Representation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification with Representation Model\n",
        "\n",
        "Here, we'll focus on binary sentiment classification of rotten tomatoes movie reviews.\n",
        "\n",
        "We can accomplish this task in two ways:\n",
        "\n",
        "### 1. Perform classification directly with a task-specific model\n",
        "\n",
        "### 2. Perform classification indirectly with general-purpose embeddings\n",
        "\n",
        "We'll use pre-trained models for now."
      ],
      "metadata": {
        "id": "UVZMD0pFL_xB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNMCZKOILYho",
        "outputId": "29a00bc8-1eef-4967-9076-d275f7230e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8530\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Importing the dataset\n",
        "!pip install datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load Rotten Tomatoes Moview Review dataset\n",
        "data = load_dataset('rotten_tomatoes')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a Task-specific model\n",
        "\n",
        "We'll use the `Twitter-RoBERTa-base for Sentiment Analysis` model. This is a RoBERTa model fine-tuned on tweets for sentiment analysis."
      ],
      "metadata": {
        "id": "syquBAq9RXVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "2qirl_IZNSmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8439ad9e-2e52-4af6-e9b5-82c129d46e46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model\n",
        "from transformers import pipeline\n",
        "\n",
        "# Path to our model\n",
        "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "# Load model into pipeline\n",
        "pipe = pipeline(\n",
        "    model=model_path,\n",
        "    tokenizer=model_path,\n",
        "    top_k=None,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiAexBRbSCPC",
        "outputId": "9b96f567-099b-44c2-cec0-7de7364202f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers.pipelines.pt_utils import KeyDataset"
      ],
      "metadata": {
        "id": "5ZRvc3qCStr1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = data['train']['text'][0]"
      ],
      "metadata": {
        "id": "rQh9kGHNXiOf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = pipe(sample)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BWzW6ZnX-_N",
        "outputId": "fdffd37e-6240-48d6-c93e-13a2a2f076ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'positive', 'score': 0.9073736071586609},\n",
              "  {'label': 'neutral', 'score': 0.0880218893289566},\n",
              "  {'label': 'negative', 'score': 0.00460449093952775}]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best sentiment prediction\n",
        "best_prediction = max(output[0], key=lambda x: x['score'])\n",
        "\n",
        "# Print only the most confident sentiment\n",
        "print(f\"Predicted Sentiment: {best_prediction['label']} (Confidence: {best_prediction['score']:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUfOVieeYHCz",
        "outputId": "0939e7a2-7a19-4a6d-8e35-68d46e23d9d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sentiment: positive (Confidence: 0.91)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model classifies text into `positive`, `negative` and `neutral` categories."
      ],
      "metadata": {
        "id": "X82U9L4bir76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A list to store predictions\n",
        "y_pred = []\n",
        "\n",
        "# Iterate through test dataset\n",
        "for output in tqdm(pipe(data['test']['text']), total=len(data['test'])):\n",
        "    # Ensure correct label matching\n",
        "    if output[0]['label']=='positive':\n",
        "        if output[1]['label']=='negative':\n",
        "            negative_score = output[1]['score']\n",
        "            positive_score = output[0]['score']\n",
        "        else:\n",
        "            negative_score = output[2]['score']\n",
        "            positive_score = output[0]['score']\n",
        "    elif output[0]['label']=='negative':\n",
        "        if output[1]['label']=='positive':\n",
        "            negative_score = output[0]['score']\n",
        "            positive_score = output[1]['score']\n",
        "        else:\n",
        "            negative_score = output[0]['score']\n",
        "            positive_score = output[2]['score']\n",
        "    else:\n",
        "        if output[1]['label']=='negative':\n",
        "            negative_score = output[1]['score']\n",
        "            positive_score = output[2]['score']\n",
        "        else:\n",
        "            negative_score = output[2]['score']\n",
        "            positive_score = output[1]['score']\n",
        "    # Get predicted class (0=Negative, 1=Positive)\n",
        "    assignment = np.argmax([negative_score, positive_score])\n",
        "    y_pred.append(assignment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyKIaIUhKm_P",
        "outputId": "07effbbe-0ca9-4b20-9d37-409a23958e9d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1066/1066 [00:00<00:00, 139557.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A list to store predictions\n",
        "y_pred = []\n",
        "\n",
        "# Iterate through test dataset\n",
        "for output in tqdm(pipe(data['test']['text']), total=len(data['test'])):\n",
        "    # Convert output into a dictionary for easy lookup\n",
        "    scores = {entry['label']: entry['score'] for entry in output}\n",
        "\n",
        "    # Extract scores safely\n",
        "    negative_score = scores.get('negative', 0)  # Default to 0 if not found\n",
        "    positive_score = scores.get('positive', 0)\n",
        "\n",
        "    # Get predicted class (0 = Negative, 1 = Positive)\n",
        "    assignment = np.argmax([negative_score, positive_score])\n",
        "    y_pred.append(assignment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEOpJKNpiCQd",
        "outputId": "de9e5613-5cd1-40fb-d200-c5fed5cc72d5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1066/1066 [00:00<00:00, 109699.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the General Output Format\n",
        "\n",
        "When we use `pipe(text)`, the model gives us an output list where each item is a dictionary like this:\n",
        "\n",
        "```\n",
        "[{'label': 'POSITIVE', 'score': 0.98}]\n",
        "```\n",
        "or\n",
        "\n",
        "```\n",
        "[{'label': 'NEGATIVE', 'score': 0.85}]\n",
        "```\n",
        "Now, the problem is:\n",
        "\n",
        "We don't know for sure if 'NEGATIVE' is always at index 0 and 'POSITIVE' is at index 1. The order might change depending on the model output.\n",
        "\n",
        "Hence, we need o check the output list to check the order of class labels before assigning the scores.\n",
        "\n",
        "We check the first prediction (`output[0]`).\n",
        "If it's 'NEGATIVE', we take `output[0]['score']` as the negative score and `output[1]['score']` as the positive score. Otherwise, we swap them.\n",
        "\n",
        "**Example Scenarios**\n",
        "\n",
        "1. Example 1: Model Outputs NEGATIVE First\n",
        "\n",
        "```\n",
        "output = [{'label': 'NEGATIVE', 'score': 0.80}, {'label': 'POSITIVE', 'score': 0.20}]\n",
        "```\n",
        "`output[0]['label'] == 'NEGATIVE'`, so:\n",
        "\n",
        "```\n",
        "negative_score = 0.80  # output[0]['score']\n",
        "positive_score = 0.20  # output[1]['score']\n",
        "```\n",
        "\n",
        "2. Example 2: Model Outputs POSITIVE First\n",
        "\n",
        "```\n",
        "output = [{'label': 'POSITIVE', 'score': 0.75}, {'label': 'NEGATIVE', 'score': 0.25}]\n",
        "```\n",
        "\n",
        "`output[0]['label'] == 'POSITIVE'`, so we enter the else block:\n",
        "\n",
        "```\n",
        "negative_score = 0.25  # output[1]['score']\n",
        "positive_score = 0.75  # output[0]['score']\n",
        "```\n",
        "\n",
        "**The labels in the dictionary are ordered by their scores.**\n",
        "\n",
        "This means, we won't have the output for all the texts in the same format."
      ],
      "metadata": {
        "id": "klMhNH8TTvk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_performance(y_true, y_pred):\n",
        "    \"\"\"Create and print classification report\"\"\"\n",
        "    report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=['Negative Review', 'Positive Review']\n",
        "    )\n",
        "    print(report)"
      ],
      "metadata": {
        "id": "LbMmhZljLc1t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_performance(data['test']['label'], y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdr1gk22S7-S",
        "outputId": "5ab3c25e-a207-465a-98c2-af69d75273e5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.76      0.88      0.81       533\n",
            "Positive Review       0.86      0.72      0.78       533\n",
            "\n",
            "       accuracy                           0.80      1066\n",
            "      macro avg       0.81      0.80      0.80      1066\n",
            "   weighted avg       0.81      0.80      0.80      1066\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using another pre-trained model\n",
        "\n",
        "Le's use the `distilbert/distilbert-base-uncased-finetuned-sst-2-english` model this time."
      ],
      "metadata": {
        "id": "8vZwAx6WbR5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model\n",
        "model_path = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english'\n",
        "\n",
        "# Creating a pipeline\n",
        "pipe_distilbert = pipeline(\n",
        "    'sentiment-analysis',\n",
        "    model=model_path,\n",
        "    tokenizer=model_path,\n",
        "    top_k=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOWOt8CXYPf_",
        "outputId": "2cb51e2b-7ebb-40d0-9a93-05e90c3fed5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "another_sample = data['validation']['text'][-1]\n",
        "sample_label = data['validation']['label'][-1]\n",
        "print('Text\\n',another_sample)\n",
        "print('Label: ', sample_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhPl2gNsby_F",
        "outputId": "447a93e3-179b-4ab7-de35-6c5f4f538f0f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text\n",
            " the feature-length stretch . . . strains the show's concept .\n",
            "Label:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = pipe_distilbert(another_sample)\n",
        "model_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGV9RVQncFvJ",
        "outputId": "cfa6cb38-dba5-49c4-8e97-7c26c8adcb64"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'NEGATIVE', 'score': 0.9998082518577576},\n",
              "  {'label': 'POSITIVE', 'score': 0.00019182452524546534}]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best sentiment prediction\n",
        "best_prediction = max(model_output[0], key=lambda x: x['score'])\n",
        "\n",
        "# Print only the most confident sentiment\n",
        "print(f\"Predicted Sentiment: {best_prediction['label']} (Confidence: {best_prediction['score']:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTH7hO1BcV5T",
        "outputId": "413e2f76-06db-4910-c3d9-b1b57a657672"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sentiment: NEGATIVE (Confidence: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "\n",
        "# A list to store predictions\n",
        "y_pred = []\n",
        "\n",
        "# Iterate through test dataset\n",
        "for output in tqdm(pipe_distilbert(data['test']['text']), total=len(data['test'])):\n",
        "    # Ensure correct label matching\n",
        "    if output[0]['label']=='NEGATIVE':\n",
        "        negative_score = output[0]['score']\n",
        "        positive_score = output[1]['score']\n",
        "    else:\n",
        "        negative_score = output[1]['score']\n",
        "        positive_score = output[0]['score']\n",
        "    # Get predicted class (0=Negative, 1=Positive)\n",
        "    assignment = np.argmax([negative_score, positive_score])\n",
        "    y_pred.append(assignment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_TOkz5Wcdkm",
        "outputId": "6a08022a-7989-4137-dfab-365ff42df63d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1066/1066 [00:00<00:00, 117794.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_performance(data['test']['label'], y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfpzPMuicsbT",
        "outputId": "e8f0bb36-0c95-413a-8d8f-1eaaa2b11546"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.89      0.90      0.90       533\n",
            "Positive Review       0.90      0.89      0.90       533\n",
            "\n",
            "       accuracy                           0.90      1066\n",
            "      macro avg       0.90      0.90      0.90      1066\n",
            "   weighted avg       0.90      0.90      0.90      1066\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that both the models are performing well, considering they aren't trained on the dataset. DistilBERT performs better because it was fine-tuned on the domain data.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Text Classification Using Embedding Models\n"
      ],
      "metadata": {
        "id": "YYz32aQNjElq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RPo49GddcyX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}